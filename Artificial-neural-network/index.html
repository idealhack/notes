<!DOCTYPE html>
<html lang="zh-Hans" class="han-init">
	<head>
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<title>Artificial neural network • idealhack’s notes</title>
		<link rel="stylesheet" media="all" href="//cdnjs.cloudflare.com/ajax/libs/Han/3.2.7/han.min.css">
	</head>
	<body>
		<p>
			<a href="/">HOME</a>
		</p>
		<p>
			This is a work in progress.
			It's generated from Markdown <a href="https://github.com/idealhack/notes">source</a>
			by <a href="https://github.com/idealhack/nvt">nvt</a>.
		</p>

<h1>Artificial neural network</h1>

<h2>Overview</h2>

<ul>
<li><a href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">人工神经网络 - 维基百科</a></li>
</ul>

<h2>Frameworks</h2>

<ul>
<li><a href="https://github.com/rbgirshick/py-faster-rcnn">rbgirshick/py-faster-rcnn: Faster R-CNN (Python implementation) &ndash; see https://github.com/ShaoqingRen/faster_rcnn for the official MATLAB version</a></li>
<li><a href="https://github.com/anishathalye/neural-style">anishathalye/neural-style: Neural style in TensorFlow!</a></li>
<li><a href="https://github.com/davheld/GOTURN">davheld/GOTURN: Source code for paper: Learning to Track at 100 FPS with Deep Regression Networks, Held, et al. ECCV 2016</a></li>
<li><a href="https://github.com/kaonashi-tyc/zi2zi">kaonashi-tyc/zi2zi: Learning Chinese Character style with conditional GAN</a></li>
<li><a href="https://github.com/koth/kcws">koth/kcws: Deep Learning Chinese Word Segment</a></li>
<li><a href="https://github.com/luanfujun/deep-photo-styletransfer">luanfujun/deep-photo-styletransfer: Code and data for paper &ldquo;Deep Photo Style Transfer&rdquo;: https://arxiv.org/abs/1703.07511</a></li>
<li><a href="https://github.com/tonybeltramelli/pix2code">tonybeltramelli/pix2code: pix2code: Generating Code from a Graphical User Interface Screenshot</a></li>
<li><a href="https://github.com/satoshiiizuka/siggraph2016_colorization">satoshiiizuka/siggraph2016_colorization: Code for the paper &lsquo;Let there be Color!: Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simultaneous Classification&rsquo;.</a></li>
<li><a href="https://github.com/nagadomi/waifu2x">nagadomi/waifu2x: Image Super-Resolution for Anime-Style Art</a></li>
<li><a href="https://github.com/lllyasviel/style2paints">lllyasviel/style2paints: sketch + style = paints</a></li>
<li><a href="https://github.com/MG2033/ShuffleNet">MG2033/ShuffleNet: ShuffleNet Implementation in TensorFlow</a></li>
<li><a href="https://github.com/emilwallner/Screenshot-to-code-in-Keras">emilwallner/Screenshot-to-code-in-Keras: A neural network that transforms a screenshot into a static website</a></li>
</ul>

<h2>Papers</h2>

<ul>
<li><a href="https://arxiv.org/abs/1510.00149">Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding</a></li>
<li><a href="https://arxiv.org/abs/1602.07360">SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &amp;lt;0.5MB model size</a></li>
</ul>

<h2>Resources</h2>

<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650720758&amp;idx=1&amp;sn=3004c425e0d427f4900a182d74bed31d">神经网络快速入门：什么是多层感知器和反向传播？</a></li>
<li><a href="https://segmentfault.com/a/1190000004524085">用神经网络实现能够自主避让障碍的生物 - noiron&rsquo;s blog - SegmentFault</a></li>
<li><a href="https://github.com//hunkim/deep_architecture_genealogy">hunkim/deep_architecture_genealogy: Deep Learning Architecture Genealogy Project</a></li>
<li><a href="http://karpathy.github.io/neuralnets/">Hacker&rsquo;s guide to Neural Networks</a></li>
</ul>


		<script src="//cdnjs.cloudflare.com/ajax/libs/Han/3.2.7/han.min.js"></script>
	</body>
</html>
